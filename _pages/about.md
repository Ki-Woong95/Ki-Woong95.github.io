---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
üëÄ Hello! I‚Äôm **Ki Woong Moon**, 
=====

I'm a third-year Ph.D. student in **Linguistics** at the University of Arizona, where I‚Äôm also beginning my journey toward a **Master‚Äôs in Human Language Technology (HLT)**.

My research lives at the intersection of **phonetics**, **speech technology**, and **computational linguistics**. I‚Äôm especially interested in incorporating speech features into computational models to enhance the performance. Also, I am deeply intrigued by analyzing speech data using statistical methods to answer fascinating questions we haven't answered.

Lately, I‚Äôve been diving deep into the phenomenon of **speech reduction** and exploring ways to adapt ASR models to more accurately interpret reduced and variable speech patterns. My goal is to bridge the gap between messy human speech and machine understanding.




Academic Journey üéì
=====
My academic journey in Linguistics began in 2014, sparked by a deep fascination with human speech‚Äîboth its production and perception.üó£Ô∏è

During my master‚Äôs program, I explored the speech production of non-native English speakers, focusing on how disfluency phenomena (e.g., filled pauses, hesitations, repetitions) relate to prosodic patterns.

In my Ph.D. studies, I shifted to native English speakers, examining both production and perception. I ran lexical decision experiments to study how American English speakers respond to British English stimuli. 

I also conducted acoustic analyses of the word "*just*" in spontaneous speech, investigating how surrounding segments and word predictability influence its reduction and phonetic realization. 

Currently, I‚Äôm developing ASR models that better handle spontaneous speech. This work bridges linguistic theory and speech technology by incorporating acoustic insights into widely-used models like Wav2Vec and Whisper. 

In the future, I would like to pursue my research on both **acoustic phonetics** and **speech technology**. My ultimate goal of researching these areas would be generalizing the technology by reducing or minimizing the bias it has due to the limited access of the data. In other words, I want to contribute on generalization of the speech technology by incorporating linguistic knowledge.


Work experience (since 2022) üè¢
======
### Graduate Research Assistant in Douglass Phonetics Lab (Aug 2022 - Jan 2025)
  * Conducted speech perception experiment
  * Analyzed speech data using statistical method
  * Organized lab meeting
  * Supervised undegraduate research assistants

### Internship at XRI Global Inc (Jan 2025 - May 2025)
  * Collecting publicly available speech data for low-resources languages (African, Southeast Asia, and South American)
  * Preprocessing speech data and fine-tuning pre-trained model (e.g., Whisper) on low-resource languages
  * Finding better approach to enhance the performance of the model (transfer learning, data augmentation)
  * Evaluate the performance of the fine-tuned ASR model





