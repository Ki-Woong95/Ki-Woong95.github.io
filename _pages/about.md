---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
üëÄ Hello! I‚Äôm **Ki Woong Moon**, 
=====

Im a third-year Ph.D. student in **Linguistics** at the University of Arizona, where I‚Äôm also beginning my journey toward a **Master‚Äôs in Human Language Technology (HLT)**.

My research lives at the intersection of **phonetics**, **speech technology**, and **computational linguistics**. I‚Äôm especially interested in utilizing speech features into computational model to enhance the performance. Also, I am deeply intrigued in analyzing speech data using statistical methods to answer fascinating questions we haven't answered.

Lately, I‚Äôve been diving deep into the phenomenon of **speech reduction** and exploring ways to adapt ASR models to more accurately interpret reduced and variable speech patterns. My goal is to bridge the gap between messy human speech and machine understanding.




Academic Journey üéì
=====
My academic journey in Linguistics began in 2014, sparked by a deep fascination with human speech‚Äîboth its production and perception.üó£Ô∏è

During my master‚Äôs program, I explored the speech production of non-native English speakers, focusing on how disfluency phenomena (e.g., filled pauses, hesitations, repetitions) relate to prosodic patterns.

In my Ph.D. studies, I shifted to native English speakers, examining both production and perception. I ran lexical decision experiments to study how American English speakers respond to British English stimuli. 

I also conducted acoustic analyses of the word just in spontaneous speech, investigating how surrounding segments and word predictability influence its reduction and phonetic realization. 

Currently, I‚Äôm developing ASR models that better handle spontaneous speech. This work bridges linguistic theory and speech technology by incorporating acoustic insights into widely-used models like Wav2Vec and Whisper. 




Skills üñ•Ô∏è
======
### Technical Skills:
  * Languages: Bash, Praat, Python, Perl, R
  * ASR/Machine Learning tools: Kaldi, Hugging Faceü§ó, Pytorch
  * General: LaTeX, MacOs, Linux(Ubuntu) Windows
  * Areas: Acoustic phonetics (speech production and perception), statistical analysis, natural language processing, audio signal processing

### Languages:
  * Korean (native)
  * English (proficient)
  * Chinese (basic)

Work experience (since 2022) üè¢
======
### Graduate Research Assistant in Douglass Phonetics Lab (Aug, 2022 - Jan, 2025)
  * Conducted speech perception experiment
  *  Analyzed speech data using statistical method
  * Organized lab meeting
  * Supervised undegraduate research assistants

### Internship at XRI Global Inc (Jan, 2025 - May, 2025)
  * Collecting publicly available speech data for low-resources languages (African, Southeast Asia, and South American)
  * Preprocessing speech data and fine-tuning pre-trained model (e.g., Whisper) on low-resources languages
  * Finding better approach to enhance the performance of the model (transfer learning, data augmentation)
  * Evaluate the performance of the fine-tuned ASR model





